\chapter{Preliminaries}
\label{:prelim}

In this chapter, we outline the data structures and other techniques which we rely on for the formulation of solutions to our own contributions.

%------------------------------------------------------------------------------
\section{Range Trees}
\label{:prelim:range-trees}

A range tree is a binary search tree that allows us to search for elements satisfying a 1D query interval. Given a set of $n$ elements, $A = \{a_1, a_2, \ldots, a_n\}$, each expressing a scalar key value $v_1, v_2, \ldots, v_n$, a range tree $T$ can identify the elements whose key falls between two values $\alpha$ and $\beta$, where $\alpha \leq \beta$.  That is, the search identified the following set:
\[
\{ a_i \in A \st \alpha \leq v_i \leq \beta \}
\]

This search can be done in $\BigOh{\log{n}}$ time with only $\BigOh{n}$ space and $\BigOh{n\log{n}}$ pre-processing time.  Reporting the matching elements can be done in $\BigOh{\log{n} + k}$ time, where $k$ is the number of elements reported. 

However, all of these properties are also true of a regular binary search on a sorted array, so why are range trees interesting? To answer this, we look at a simple example of a range tree. Suppose $A$ is a set of 2D points embedded in the plane, and that, for our query, we wish to identify all points whose $x$-coordinate is between $\alpha$ and $\beta$.  To answer this query, we can construct a range tree $T$ where each point $a_i$, $1 \leq i \leq n$ is represented by leaf node whose key value is set to the $x$-coordinate of $a_i$; that is, where $v_i = a_i.x$.

When we query $T$ for $\alpha$ and $\beta$, we identify two paths through $T$ in $\BigOh{\log{n}}$ time. The leaf with key value $\alpha$ (or with the successor value to $\alpha$, if the exact value is not present) is $a_\alpha$ and is the leftmost point in $A$ matching our query.  Similarly, the leaf with key value $\beta$ (or with the  predecessor to $\beta$, if the exact value is not present) is $a_\beta$ and is the rightmost point in $A$ matching our query. Since the leaves in a binary search tree are sorted, the sequence of points from $a_\alpha$ to $a_\beta$ are exactly the points we need to identify. We can report these points with an inorder traversal.

\begin{figure}
\begin{center}
  \includegraphics[width=0.40\textwidth]{figures/fig_pre_range1d}
  \caption{A 1D range tree and the subtrees identified by a query.}
  \label{fig:pre:range1d}
\end{center}
\end{figure}

What makes range trees such versatile structures is not simply that they identify the query elements, but rather due to the way that they group the identified elements into at most $\BigOh{\log{n}}$ disjoint subsets. These subsets are precisely the elements found in the ``inner'' subtrees along the path from $a_\alpha$ to $a_\beta$, as illustrated in Figure~\ref{fig:pre:range1d}.

With each non-leaf node of $T$, we can store additional information about the subset represented by its subtree.  The, during query time, we only need to consider the information stored at $\BigOh{\log{n}}$ nodes rather than the $\BigOh{n}$ elements they represent. Continuing our example on 2D points, with only $\BigOh{1}$ extra space per node, we could store which point has the highest $y$-coordinate in each subtree.  Then, we can use our range tree to find the highest point between two $x$-coordinates in $\BigOh{\log{n}}$ time.

We are not limited to just storing simple values with each node, however. With each node, we can associate an entire additional data structure, constructed on the elements represented by that node. In particular, we can store another range tree which is based on some other property of each element.  When we query this two-level range tree, our query at the first level identifies $\BigOh{\log{n}}$ subsets. Each subset represents elements which satisfy a particular query condition. Then, for each subset, we query the associated data structure to identify elements satisfying a second query condition.  The elements identified here satisfy both conditions. This technique can be repeated to create \emph{multi-level range trees} with more than just two levels.

The following theorems on range trees, restated from \cite{debergch5}, detail the construction and query times of multi-level range trees.

\begin{theorem}
\label{th:rangetree}
Let $P$ be a set of $n$ points in $d$-dimensional space, with $d \geq 2$. A multi-level range tree for $P$ uses $\BigOh{n \log^{d-1}{n}}$ storage and it can be constructed in $\BigOh{n \log^{d-1}{n}}$ time. With this range tree one can report the points in $P$ that lie in a rectangular query range in $\BigOh{\log^{d-1}{n} + k}$ time where $k$ is the number of reported points.
\end{theorem}

If each node of the range tree is augmented with information about the size of its subtree, then we can count the number of items within a query rectangle rather than reporting them. The following corollary summarizes this.

\begin{corollary}
\label{cor:rangetree}
Let $P$ be a set of $n$ points in $d$-dimensional space, with $d \geq 2$. A multi-level range tree for $P$ uses $\BigOh{n \log^{d-1}{n}}$ storage and it can be constructed in $\BigOh{n \log^{d-1}{n}}$ time. With this range tree one can count the points in $P$ that lie in a rectangular query range in $\BigOh{\log^{d-1}{n}}$ time.
\end{corollary}


%------------------------------------------------------------------------------
\section{Chan's Disjoint Set Data-structure}
\label{:prelim:chan}

XXX TODO

Restated with $d=2$.

\begin{theorem}[Corollary 7.3, part $i$, in Chan\cite{chan2012}]
\label{th:chan}
We can form $O(n)$ canonical subsets of total size $O(n \log{n})$ in $O(n \log{n})$ time, such that the subset of all points inside any query simplex can be reported as a union of disjoint canonical subsets $C_i$ with $\sum_i{\sqrt{|C_i|}} \leq O(\sqrt{n}\log{n})$ in time $O(\sqrt{n}\log{n})$ w.h.p. $(n)$.
\end{theorem}

XXX TODO Can I just show some example analysis here?

This structure is particularly well-suited to multi-level query structures, as we can associate additional data structures with each of the canonical subsets.

Given an associate data structure which requires $f(n)$ preprocessing space, $g(n)$ preprocessing time, and $h(n)$ query time, we have the following corollary.

\begin{corollary}
\label{cor:chan}
With each of the $k = \BigOh{n}$ canonical subsets $C_1, C_2, \ldots, C_k$ created for a canonical subsets structure, we can associate a data structure with the elements of each subset. If this associated structure requires $\BigOh{n\log^f{n}}$ preprocessing space, $\BigOh{n \log^g{n}}$ preprocessing time, and $\BigOh{\sqrt{n}\log^h{n}}$ query time, where $f, g, h \in O(1), f \leq g$, then the resulting multi-level data structure requires $\BigOh{n\log^{f+1}{n}}$ preprocessing space, $\BigOh{n\log^{g+1}{n}}$ preprocessing time, and $\BigOh{\sqrt{n}\log^{h+1}{n}}$ query time.
\end{corollary}

\begin{proof}
The preprocessing space of the structure requires $\BigOh{n \log{n}}$ space for the canonical subsets structure itself, plus
\[
\begin{split}
\sum_{i=1}^k{|C_i| \log^f{|C_i|}}
&\leq \sum_{i=1}^k{|C_i| \log^f{n}} \\
%
&\leq \BigOh{\log^f{n}} \cdot \sum_{i=1}^k{|C_i|} \\
%
&\leq \BigOh{n\log^{f+1}{n}}
\end{split}
\]

\noindent for the associate structures, for a total space complexity of $\BigOh{n \log{n}} + \BigOh{n\log^{f+1}{n}} = \BigOh{n\log^{f+1}{n}}$.

Preprocessing time is calculated using similar reasoning, and includes the $\BigOh{n \log{n}}$ time for creating the canonical subsets structure itself, plus
\[
\begin{split}
\sum_{i=1}^k{|C_i| \log^g{|C_i|}}
&\leq \sum_{i=1}^k{|C_i| \log^g{n}} \\
%
&\leq \BigOh{\log^g{n}} \cdot \sum_{i=1}^k{|C_i|} \\
%
&\leq \BigOh{n\log^{g+1}{n}}
\end{split}
\]

\noindent for building the associate structures, for a total time complexity of $\BigOh{n \log{n}} + \BigOh{n\log^{g+1}{n}} = \BigOh{n\log^{g+1}{n}}$.

Querying requires $\BigOh{\sqrt{n}\log{n}}$ time to find the $k'$ disjoint canonical subsets representing the elements found by the top-level canonical subsets query, plus
\[
\begin{split}
\sum_{i=1}^{k'}{\BigOh{\sqrt{|C_i|}\log^h{|C_i|}}} 
&\leq \sum_{i=1}^{k'}{\BigOh{\sqrt{|C_i|}\log^h{n}}} \\
%
&\leq \BigOh{\log^h{n}} \cdot \sum_{i=1}^{k'}{\BigOh{\sqrt{|C_i|}}} \\
%
&\leq \BigOh{\sqrt{n}\log^{h+1}{n}} \\
\end{split}
\]

\noindent to query the appropriate associated data structures, for a total query time of 
\[
\BigOh{\sqrt{n}\log{n}} + \BigOh{\sqrt{n}\log^{h+1}{n}} = \BigOh{\sqrt{n}\log^{h+1}{n}}
\]

\end{proof}